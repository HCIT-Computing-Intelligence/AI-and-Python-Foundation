{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "from jieba import posseg\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))\n",
    "\n",
    "\n",
    "def idf(word):\n",
    "    eps = 1e-6\n",
    "    \n",
    "    return 1 / (np.log10(sum(1 for s in sentences if word in s)) + eps)\n",
    "\n",
    "\n",
    "def tf(word, sentence_cut):\n",
    "    return sentence_cut.count(word)\n",
    "\n",
    "\n",
    "def tfidf(word, sentence):\n",
    "    return tf(word, sentence) * idf(word)\n",
    "\n",
    "\n",
    "def get_tfidf_from_sentence(sentence_cut):\n",
    "    ## you code here\n",
    "    '''\n",
    "    return : a dictionary\n",
    "    '''\n",
    "    \n",
    "    tf_idf_words = dict()\n",
    "    \n",
    "    for c in set(sentence_cut):\n",
    "        tf_idf_words[c] = tfidf(c, sentence_cut)\n",
    "        \n",
    "    return tf_idf_words\n",
    "\n",
    "\n",
    "def get_top_tfidf(sentence_cut, ratio=0.25):\n",
    "    \"\"\"\n",
    "    return : [(word1, tfidf_value), (word2, tfidf_value)]\n",
    "    \"\"\"\n",
    "    tfidf_value = get_tfidf_from_sentence(sentence_cut)\n",
    "    \n",
    "    top_ratio = ratio\n",
    "    \n",
    "    return sorted(tfidf_value.items(), key=lambda x: x[1], reverse=True)[:int(len(tfidf_value)*top_ratio)]\n",
    "\n",
    "\n",
    "def is_name(cut_word):\n",
    "    w, _type = list(posseg.cut(cut_word))[0]\n",
    "    \n",
    "    if _type == 'nr': return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "# def get_names_from_sentence(sentence: str):\n",
    "#     names = []\n",
    "    \n",
    "#     for w_t in posseg.cut(cut_word):\n",
    "#         w, t = tuple(w_t)\n",
    "        \n",
    "#         if t ++ \n",
    "#     return [w for w in cut_sentence if is_name(w)]\n",
    "\n",
    "\n",
    "# we do some refractor\n",
    "def get_name_correlate(sentence: str):\n",
    "    \n",
    "    name_correlate = defaultdict(lambda : defaultdict(int))\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    for w_t in posseg.cut(sentence):\n",
    "        w, t = tuple(w_t)\n",
    "        \n",
    "        if t == 'nr': names.append(w)\n",
    "            \n",
    "    for n in names:\n",
    "        for w in names:\n",
    "            if n == w: continue\n",
    "                \n",
    "            name_correlate[n][w] += 1 \n",
    "    \n",
    "    return name_correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open('dataset/article_9k.txt')\n",
    "CHARACTERS = content.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = CHARACTERS.split('\\n')\n",
    "all_sentences_with_cut_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences_with_cut_tokens = [cut(s) for s in sentences]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
